### DCP PR:

***Leave this blank until the RFC is approved** then the **Author(s)** must create a link between the assigned RFC number and this pull request in the format:*

`[dcp-community/rfc#](https://github.com/HumanCellAtlas/dcp-community/pull/<PR#>)`

# Matrix Service

## Summary

The existing Matrix Service is a prototype of a Data Coordination Platform (DCP) feature that enables data consumers to perform integrative analysis across Human Cell Atlas (HCA) projects. In its current implementation, this is achieved by delivering a RESTful API that enables data consumers to generate expression matrices defined by a metadata query against an index of cells. This RFC details the prototype's major design decisions surrounding i) the Matrix Service API and ii) the service's cell-centric data model.

## Authors

[Calvin Nhieu](cnhieu@chanzuckerberg.com)

[Marcus Kinsella](mkinsella@chanzuckerberg.com)

## Shepherd
 [Brian Raymor](braymor@chanzuckerberg.com)

## Motivation

The HCA DCP ingests, processes, and stores single-cell data, making that data easily available to a wide audience of researchers. The single-cell data type of greatest interest to most researchers is the expression matrix, the cell-by-gene expression values that are the starting point for many downstream analyses (e.g. cell type annotation, differential expression, etc.). To support this most commonly requested data type, the DCP offers a specialized interface, the DCP Matrix Service, which enables investigators to easily access and perform integrative analysis across HCA expression data.

### User Stories

As a user with a keyboard, I would like gene expression data from the DCP so that I can perform downstream integrative analysis across HCA experiments.

- I would like to generate an expression matrix comprised of cells that satisfy a set of metadata conditions.
- I would like to generate metadata providing the experimental and scientific context about the cells in my matrix.
- I would like to generate my matrix in a format that is compatible with standard single-cell analysis tools.
- I would like to generate my matrix in a reasonable amount of time; in general, on the order of minutes, not hours.

As a user with a pipette, I would like gene expression data from the DCP.

- To support this set of users, an interface via the HCA Data Browser will leverage the API to provide static matrix products.

## Scientific "guardrails"

*Describe recommended or mandated review from HCA Science governance to ensure that the RFC addresses the needs of the scientific community.*

## Detailed Design

### Overview

The Matrix Service enables on-the-fly expression matrix generation via a [RESTful API](https://matrix.data.humancellatlas.org/). Through user studies and iterative development over the past year, four major requirements of matrices have been identified and must be met:

1. Matrices must enable cell-level granularity integrative analysis across data in the HCA.
1. Matrices must include rich metadata that users are interested in so that they can better understand the data they're working with.
1. Matrices must be compatible with downstream single cell analysis tools, for example in `scanpy` and `Seurat`, to further enable downstream analysis of HCA data by the wider community.
1. Performance of serving matrices must be prioritized as the scale of HCA data is anticipated to reach or exceed the order of tens of millions of cells.

The Matrix Service API is designed to fulfill these requirements in order to provide access to HCA data in a format that enables and encourages downstream integrative analysis.

The default and recommended file format for matrices generated by the service is [loom](http://loompy.org/), an HDF5 file format that is optimized for storing large omics datasets such as expression matrices and designed for consumability, for example, by exporting metadata with matrices. The Matrix Service achieves its first three goals by delivering matrices in `loom`, and other supporting formats, via an expressive API that enables users the ability to specify individual cells and desired metadata to generate a matrix for. For a detailed example, see [this user vignette](https://nbviewer.jupyter.org/github/HumanCellAtlas/matrix-service/blob/master/docs/HCA%20Matrix%20Service%20to%20Scanpy.ipynb#HCA-Matrix-Service-Loom-Output) describing a `loom` matrix generated by the service. The fourth requirement is satisfied by a lazy cache of matrices that enables the availability of previously requested matrices within minutes, if not seconds.

*Note: The current technical architecture of the service is documented [here](https://allspark.dev.data.humancellatlas.org/HumanCellAtlas/matrix-service/wikis/Technical-Architecture).*

### API

â€‹	At a high level, a request to `POST` `/matrix` will kick off an asynchronous request to generate a matrix and immediately return a `request_id` to the client. The client is able to poll `GET` `/matrix` for the status of the request and, once available, the public S3 location of the generated matrix for download. In addition to the main functionality, a set of auxiliary endpoints are made available to provide users with more information on how to use the API and the data available. Below is a summary of the API's endpoints:

*Table 1.1 Matrix Service API Endpoints for Main Functionality*

| Matrix endpoint        | Verb   | Description                                     |
| ---------------------- | ------ | ----------------------------------------------- |
| `/matrix`              | `POST` | Request the generation of an expression matrix. |
| `/matrix/<request_id>` | `GET`  | Retrieve the status and results of a request.   |

*Table 1.2 Matrix Service API Endpoint for Auxiliary Functionality*

| Auxiliary endpoint    | Verb  | Description                                                  |
| --------------------- | ----- | ------------------------------------------------------------ |
| `/filters`            | `GET` | Returns a list of available filter values.                   |
| `/filters/<filter>`   | `GET` | Returns more information about a specific filter.            |
| `/fields`             | `GET` | Returns a list of available metadata field values.           |
| `/fields/<field>`     | `GET` | Returns more information about a specific metadata field.    |
| `/formats`            | `GET` | Returns a list of available matrix formats.                  |
| `/formats/<format>`   | `GET` | Returns more information about a specific matrix format.     |
| `/features`           | `GET` | Returns a list of available expression feature types.        |
| `/features/<feature>` | `GET` | Returns more information about a specific expression feature type. |

### POST /matrix

To request a matrix, users must supply a metadata filter expression for which matching cells will be included in the generated matrix. Optionally, they may also specify a list of metadata fields to be exported per cell in the matrix, the output file format and the feature type to describe. Below is a sample request body and a description of the four fields:

```
{
	'filter': dict,
	'fields': list,
	'format': string,
	'feature': string
}
```

#### Filter

The filter object is inspired by the [Genomics Data Commons (GDC) API](https://docs.gdc.cancer.gov/API/Users_Guide/Search_and_Retrieval/#filters-specifying-the-query). To enable users the ability to express complex metadata queries, the object supports nested composition of base filter objects to create a tree of AND/OR statements. The API deviates from the GDC API specification by defining two types of base filter objects:

*Table 1.3 Base filter object types*

| Filter object     | Specification                                                |
| ----------------- | ------------------------------------------------------------ |
| Comparison Filter | {<br />   `op`: one of `[ =, !=, >, <, >=, <=, in ]`,<br />   `field`: a metadata field,<br />   `value`: string \| int \| list <br />} |
| Logical Filter    | {<br />   `op`: one of `[ and, or, not ]`,<br />   `value`: array of >=2 filter objects `if op==and|or`, filter object `if op==not` <br />} |

Comparison Filters specify a condition on a metadata field and Logical Filters implement `and`, `or` and `not` logic. Note that the `value` field of a Logical Filter accepts a base filter object and is the mechanism for nesting chains of AND/OR statements. For a Comparison Filter's `field` parameter, the list of accepted metadata filters is available at the `/filters` endpoint. More information about a filter such as a description and a set of valid values can be found at the `/filters/<filter>` endpoint. See [Auxiliary Endpoints](#auxiliary-endpoints) for more details on these.

Ex. Select all full length cells:

```
"filter": {
  "op": ">=",
  "value": "full length",
  "field": "library_preparation_protocol.end_bias"
}
```

Ex. Select all cells from the "Single cell transcriptome analysis of human pancreas" project with at least 3000 genes detected:

```
"filter": {
  "op": "and",
  "value": [
    {
      "op": "=",
      "value": "Single cell transcriptome analysis of human pancreas",
      "field": "project.project_core.project_short_name"
    },
    {
      "op": ">=",
      "value": 3000,
      "field": "genes_detected"
    }
  ]
}
```

#### Fields

Users may supply a list of metadata `field`s to be exported with their generated matrix. For `loom` formats, metadata is made available within the `loom` file itself via an adjacent attribute matrix; `mtx` and `csv` formats provide a separate CSV file to serve user requested metadata. The full list of available metadata fields is available at the [/fields endpoint](https://matrix.data.humancellatlas.org/v1/fields). More information about a specific metadata field such as a description and a set of valid values is available at the `/fields/<field>` endpoint. See [Auxiliary Endpoints](#auxiliary-endpoints) for more details on these.

#### Format

The API generates expression matrices in three formats: `loom`, `mtx` and `csv`. From the [loom](http://loompy.org/) documentation page, the format is "an efficient file format for large omics datasets", enabling the storage of large expression matrices with metadata and also supports many popular data processing programming languages. For these reasons, `loom` is the service's default and most performant format. The `mtx` format adheres to the [10x feature-barcode matrix specification](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/matrices) to enable compatibility with 10X methods from `scanpy` and `Seurat`. `csv` is supported as a raw text format for which performance may not be optimized.

#### Feature

Users are also able to specify the expression feature type, i.e. the matrix's axis label, as `gene` (default) or `transcript` names.

#### Species (proposed)

`species` is a potential fifth parameter that the endpoint may accept. Currently, `species` is not a top-level parameter and is rather specified within `filter` via the `cell_suspension.genus_species.ontology` and `cell_suspension.genus_species.ontology_label` filters. Since a distinct matrix is generated for each `species` requested, it may be a more intuitive user experience for it to be a top-level parameter. Additionally, it requires non-trivial logic for the Matrix Service to parse a complex `filter` object to determine which species are requested, i.e. which species to generate a matrix for. In order to simplify the user's mental model of the API as well as the service's logic complexity, `species` is proposed as a fifth request body parameter.

Note: Currently, supported species are _Homo Sapiens_ and _Mus Musculus_.

#### Response

The response object returns a `request_id` that users can use to retrieve the status and results of a request by supplying it to the `GET` `/matrix` endpoint. A `status` and `message` field are also supplied to inform the user whether the request started successfully or not.

*Note about multiple species:*
If a request selects cells from multiple species, the Matrix Service will generate one matrix per species and thus return multiple `request_id`s. The convention here is for the human matrix to be reflected in `request_id` and all other species matrices to be reflected in a list of `request_id`s via `non_human_request_ids`.

```
{
	'request_id': string,
	'non_human_request_ids': list,
	'status': one of ["In Progress", "Complete", "Failed", "Expired"],
	'message': string
}
```

### GET /matrix/<request_id>

A `request_id` returned by the `POST` endpoint can be supplied as a URL parameter to this endpoint to retrieve the status and results of the request.

#### Response

```
{
	'request_id': string,
	'status': one of ["In Progress", "Complete", "Failed", "Expired"],
	'matrix_url': string,
	'message': string
}
```

The response returns the `request_id`, a `status` and `message` similar to the response of the `POST /matrix` endpoint. If the `status` of the request is `Complete`, then `matrix_url` will be populated with the public S3 download URL to the generated matrix. Otherwise, an empty string will be returned and a message explaining the status or an error that interrupted the request.

### Auxiliary Endpoints

To improve user experience, for each of the four POST body parameters, a pair of `GET` endpoints are available to provide more information about the parameter and the set of accepted values. For example, `GET /filters` and `GET /filters/<filter>` provide respectively, the full list of acceptable filters and information about a specific filter. For filters that take on categorical (string) values, the latter will return a description of the filter, the set of valid values for the filter, and a distribution of cell counts across the values. Numeric filters, such as `genes_detected`, will return a description and the maximum and minimum values across all cells . An example response from each endpoint illustrates this:

Ex. GET /filters

```
[
    "cell_suspension.provenance.document_id",
    "genes_detected",
    "total_umis",
    "barcode",
    "emptydrops_is_cell",
    "specimen_from_organism.provenance.document_id",
    "cell_suspension.genus_species.ontology",
    "cell_suspension.genus_species.ontology_label",
    "donor_organism.provenance.document_id",
    "donor_organism.human_specific.ethnicity.ontology",
    "donor_organism.human_specific.ethnicity.ontology_label",
    "donor_organism.diseases.ontology",
    "donor_organism.diseases.ontology_label",
    "donor_organism.development_stage.ontology",
    "donor_organism.development_stage.ontology_label",
    "donor_organism.sex",
    "donor_organism.is_living",
    "derived_organ_ontology",
    "derived_organ_label",
    "derived_organ_parts_ontology",
    "derived_organ_parts_label",
    "specimen_from_organism.organ.ontology",
    "specimen_from_organism.organ.ontology_label",
    "specimen_from_organism.organ_parts.ontology",
    "specimen_from_organism.organ_parts.ontology_label",
    "library_preparation_protocol.provenance.document_id",
    "library_preparation_protocol.input_nucleic_acid_molecule.ontology",
    "library_preparation_protocol.input_nucleic_acid_molecule.ontology_label",
    "library_preparation_protocol.library_construction_method.ontology",
    "library_preparation_protocol.library_construction_method.ontology_label",
    "library_preparation_protocol.end_bias",
    "library_preparation_protocol.strand",
    "project.provenance.document_id",
    "project.project_core.project_short_name",
    "project.project_core.project_title",
    "analysis_protocol.provenance.document_id",
    "dss_bundle_fqid",
    "bundle_uuid",
    "bundle_version",
    "file_uuid",
    "file_version",
    "analysis_protocol.protocol_core.protocol_id",
    "analysis_working_group_approval_status"
]
```

Ex. Categorical filter: GET /filters/project.project_core.project_short_name

```
{
    "cell_counts": {
        "1M Immune Cells": 782859,
        "Fetal/Maternal Interface": 546183,
        "HPSI human cerebral organoids": 156936,
        "Human Hematopoietic Profiling": 41331,
        "HumanColonicMesenchymeIBD": 61604,
        "HumanTissueTcellActivation": 267360,
        "KidneySingleCellAtlas": 341079,
        "Reprogrammed_Dendritic_Cells": 15744,
        "Single cell RNAseq characterization of cell types produced over time in an in vitro model of human inhibitory interneuron differentiation.": 1733,
        "Single cell transcriptome analysis of human pancreas": 2544,
        "SingleCellLiverLandscape": 299486,
        "Tissue stability": 73515,
        "WongAdultRetina": 41350
    },
    "field_description": "A short name for the project.",
    "field_name": "project.project_core.project_short_name",
    "field_type": "categorical"
}
```

Ex. Numeric filter: GET /filters/genes_detected

```
{
    "field_description": "Count of genes with a non-zero count.",
    "field_name": "genes_detected",
    "field_type": "numeric",
    "maximum": 13108,
    "minimum": 2
}
```

### Cell-centric Index

To realize the metadata querying interface required by the API, the Matrix Service maintains an index of cells capable of answering questions about a cell's experimental and scientific background. In particular, a cell is represented as the fundamental entity in the database and maintains foreign key references to various tables representing metadata facets. To promote readability of the index, table field names are simplified versions of their full canonical metadata names. Below is the current database table structure:

*Table 2.1 Cell-centric index schema*

| Table name          | Fields                                                       | Canonical Metadata Name                                      | Description                                                  |
| ------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| cell                | cellkey (PK)<br />cellsuspensionkey<br/>projectkey<br/>librarykey<br/>analysiskey<br/>file_uuid<br/>file_version<br/>barcode<br/>genes_detected<br/>total_umis<br/>emptydrops_is_cell | N/A (derived field)<br />cell_suspension.provenance.document_id<br/>project.provenance.document_id<br/>library_preparation_protocol.provenance.document_id<br />analysis_protocol.provenance.document_id<br />file_uuid<br />file_version<br />N/A (not metadata)<br />N/A (not metadata)<br />N/A (not metadata)<br />N/A (not metadata) | Each row represents a single cell and is described by foreign key references to other facet tables representing metadata fields. |
| expression          | cellkey (PK)<br />featurekey<br/>exprtype<br/>exprvalue      | N/A (derived field)<br />N/A (not metadata)<br />N/A (not metadata)<br />N/A (not metadata) | Stores gene expression values. Each row specifies a cell, feature (e.g. gene) and expression value. |
| feature             | featurekey (PK)<br />featurename<br/>featuretype<br/>chromosome<br/>featurestart<br/>featureend<br/>isgene<br/>genus_species | N/A (not metadata)<br />N/A (not metadata)<br />N/A (not metadata)<br />N/A (not metadata)<br />N/A (not metadata)<br />N/A (not metadata)<br />N/A (not metadata)<br />cell_suspension.genus_species.ontology_label | Describes gene and transcript information for supported species. Data is populated from GENCODE GTF annotation files. |
| analysis            | analysiskey (PK)<br />bundle_fqid<br/>bundle_uuid<br/>bundle_version<br/>protocol<br/>awg_disposition | analysis_protocol.provenance.document_id<br />dss_bundle_fqid<br />bundle_uuid<br />bundle_version<br />analysis_protocol.protocol_core.protocol_id<br />analysis_working_group_approval_status | Represents an analysis bundle.                               |
| donor               | donorkey (PK)<br />ethnicity_ontology<br/>ethnicity_label<br/>diseases_ontology<br/>diseases_label<br/>development_stage_ontology<br/>development_stage_label<br/>sex<br/>is_living | donor_organism.provenance.document_id<br />donor_organism.human_specific.ethnicity.ontology<br />donor_organism.human_specific.ethnicity.ontology_labe<br />donor_organism.diseases.ontology<br />donor_organism.diseases.ontology_label<br />donor_organism.development_stage.ontology<br />donor_organism.development_stage.ontology_label<br />donor_organism.sex<br />donor_organism.is_living | Represents an experiment donor.                              |
| specimen            | specimenkey (PK)<br />donorkey<br/>organ_ontology<br/>organ_label<br/>organ_parts_ontology<br/>organ_parts_label<br/>diseases_ontology<br/>diseases_label | specimen_from_organism.provenance.document_id<br />donor_organism.provenance.document_id<br />specimen_from_organism.organ.ontology<br />specimen_from_organism.organ.ontology_label<br />specimen_from_organism.organ_parts.ontology<br />specimen_from_organism.organ_parts.ontology_label<br />donor_organism.diseases.ontology<br />donor_organism.diseases.ontology_label | Represents a specimen biomatieral. The relationship between specimen and donor is many-to-one. |
| cell_suspension     | cellsuspensionkey (PK)<br />specimenkey<br/>derived_organ_ontology<br/>derived_organ_label<br/>derived_organ_parts_ontology<br/>derived_organ_parts_label<br/>genus_species_ontology<br/>genus_species_label | cell_suspension.provenance.document_id<br/>specimen_from_organism.provenance.document_id<br />N/A (derived field)<br />N/A (derived field)<br />N/A (derived field)<br />N/A (derived field)<br />cell_suspension.genus_species.ontology<br />cell_suspension.genus_species.ontology_label | Represents a cell suspension biomaterial. The relationship between a cell suspension and a specimen is many-to-one. |
| library_preparation | librarykey (PK)<br />input_nucleic_acid_ontology<br/>input_nucleic_acid_label<br/>construction_approach_ontology<br/>construction_approach_label<br/>end_bias<br/>strand | library_preparation_protocol.provenance.document_id<br />library_preparation_protocol.input_nucleic_acid_molecule.ontology<br />library_preparation_protocol.input_nucleic_acid_molecule.ontology_label<br />library_preparation_protocol.library_construction_method.ontology<br />library_preparation_protocol.library_construction_method.ontology_labelibrary_preparation_protocol.end_bias<br />library_preparation_protocol.strand | Represents a library preparation method.                     |
| project             | projeckey (PK)<br />short_name<br/>title                     | project.provenance.document_id<br/>project.project_core.project_short_name<br />project.project_core.project_title | Represents a project/scientific experiment.                  |
| publication         | projectkey (PK)<br />pub_title<br/>pub_doi                   | project.provenance.document_id<br/>project.publications.title<br />project.publications.doi | Represents a publication associated with a project.          |
| contributor         | projectkey (PK)<br />cont_name<br/>cont_institution          | project.provenance.document_id<br/>project.contributors.name<br />project.contributors.institution | Represents a scientific contributor associated with a project. |

### Amazon Redshift

In anticipation of the scale of HCA data, the index is built on Amazon Redshift, a highly scalable, columnar database. The choice of a columnar database enables efficient querying across column attributes, i.e. metadata fields according to the proposed table design. Hosting this service on AWS provides on-demand scaling capabilities such as [Concurrency Scaling](https://aws.amazon.com/blogs/aws/new-concurrency-scaling-for-amazon-redshift-peak-performance-at-all-times/). This architecture was chosen for its integration with AWS services, ability to seamlessly handle parallel requests and complete large metadata queries within minutes. See [Prior Art](#prior-art) for alternatives explored in the past.

### Building the Index

The index is populated via an ETL job that extracts expression data and metadata from analysis bundles in the DSS and transforms them into the cell-based schema defined above. Additionally, feature data such as genes and transcripts are retrieved for supported species from [public GENCODE annotation files](https://www.gencodegenes.org/human/). These three data sources, expression data, metadata and feature data, distinguish three processes that make up the ETL job.

#### Expression data

*Related tables:* `cell`, `expression`

Data for cell and expression tables are derived from [Secondary Analysis Pipeline](https://github.com/HumanCellAtlas/skylab) outputs. The specific files parsed depend on the type of analysis pipeline and where expression data is stored in an analysis bundle.

*Table 2.2 Expression data parsing methods for various analysis pipelines*

| Analysis Pipeline | Consumed files                                               | Expression Data                                              | Cell ID                                                      |
| ----------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| SS2               | `cell_suspension_*.json`<br />`*.isoforms.results`<br />`*.genes.results` | For SS2 pipelines, expression counts are parsed for both gene and transcript IDs from `*.genes.results` and `*.isoforms.results` files. | Since SS2 bundles conventionally contain one cell per bundle, the `cell_suspension.provenance.document_id` is used as a cell's unique identifier within the index. |
| Optimus           | `*zarr*`<br />`empty_drops_result.csv`                       | For Optimus pipelines, expression data is parsed from the pipeline generated `zarr` according to this [specification](https://github.com/HumanCellAtlas/skylab/blob/master/docs/matrix_format_spec.md) maintained by Secondary Analysis and Matrix teams. However, a large majority of the barcodes represented in the `zarr`do not represent genuine cells according to `empty_drops_result.csv`  (in one example bundle, only ~1% of rows are suggested to be real cells). To enable users to perform their own filtering on a reasonable set of barcodes while not delivering an abundance of low-quality data, a barcode is included in the index if the UMI count reported in `empty_drops_result.csv` is greater than 100, as entires with less are almost certainly artifactual. Additionally, users may still interact with these parameters via the `cell` table fields `barcode`, `total_umis` and `empty_drops_iscell`. | Within the index, cells are identified by a unique `cellkey` deterministically generated and managed by the Matrix Service. The current algorithm for generating an Optimus `cellkey` is the MD5 hash of the `bundle_uuid` and `barcode`. To ensure uniqueness and deterministic generation, the following assumptions must be true:<br /><br />1. A `bundle_uuid` must be preserved across updates and revisions to the bundle.<br />2. Barcodes are unique within a bundle.<br /><br />It should be noted that the event of a project reingestion does not maintain assumption (1) since bundle UUIDs are regenerated which results in generating a different `cellkey` for the same cell. The current response to this is to rebuild the index for the reingested project. |

#### Metadata

*Related tables:* `analysis`, `donor`, `specimen`, `cell_suspension`, `library_preparation`, `project`, `publication`, `contributor`

Metadata are parsed directly from metadata JSON files available in primary and analysis bundles. These fields are identifiable as fields with a valid _Canonical Metadata Names_ mapping in _Table 2.1_. The exceptions are "derived fields" such as `derived_organ_*` that require a degree of intellectual reasoning of the experiment to determine an accurate value. For example, the value of `derived_organ_ontology` may differ from the value of `organ_ontology`, which is read directly from `specimen_from_organism.organ.ontology`, as it is determined by the presence of organoids and/or cell lines in the experiment.

Metadata entities are identified by their `*.provenance.document_id` (DIDs) which are consistently used as primary keys in the schema defined in *Table 2.1*. A similar set of assumptions applied to _Cell IDs_ described in *Table 2.2* apply to these IDs as well:

1. DIDs are unique for distinct metadata entities.
2. DIDs are preserved across all bundles updates to preserve referential integrity of metadata entities over time.
3. DIDs are versioned so that metadata can be synchronized across DCP services.

A discussion should be had with the DCP regarding the feasibility of DIDs meeting these assumptions. (1) is potentially at risk as it is possible for the same metadata entity to have different DIDs in separate projects. (2) may be true and requires confirmation from Wranglers/Ingest. Work to satisfy (3) is ongoing and tracked [here](https://github.com/HumanCellAtlas/ingest-central/issues/598).

#### Feature data

*Populated tables:* `feature`

Feature data is not parsed from files in primary or analysis bundles. Rather, they are retrieved from GENCODE and specifically, from the primary annotation GTF matching the version used by Secondary Analysis, i.e. [v27 for human](https://www.gencodegenes.org/human/release_27.html). The ETL job will download the GTF and parse gene and transcript data to populate the `feature` table. There currently is no process in place for synchronizing GTF versions between Secondary Analysis and Matrix Service.

### AUDR

The Matrix Service does not subscribe to DSS notifications favoring correctness and completeness of data over real-time availability. In practice, this translates to updating its index at a regular schedule or following significant events in the DCP such as the completion and validation of secondary analysis of a project. Outlined below are the current SOPs for AUDR operations:

#### Add

The Matrix Service supports additions for new bundles and projects by executing an ETL job for new bundle FQIDs and project UUIDs. Following indexing of a project, a project matrix for each format will be generated via the service and uploaded to the Data Browser-managed `project-assets.data.humancellatlas.org` S3 bucket at the `project-assets/project-matrices/<project_uuid>.<genus_species>.<format>` prefix. This enables the direct download of project matrices via the Data Browser.

Currently, this process initiated manually by DataOps notifying a Matrix Service developer when secondary analysis for a project has completed and the results are validated. A ticket is opened by DataOps in the Matrix Service board to track 1) project ingestion and 2) availability via the Data Browser. These two steps must also be kicked off manually by a Matrix Service developer which requires 1-2 days of engineering attention per project. A [design proposal](https://docs.google.com/document/d/1RCJo_QTeP9dysqrE2JEeI2NH7f5VTLZtB7wnC2kjo1c/edit?usp=sharing) to automate all steps and enable a DataOps or Matrix Service member to kick off the process via an API endpoint is available and [slated for completion by EOQ4 2019](https://app.zenhub.com/workspaces/dcp-5ac7bcf9465cb172b77760d9/issues/humancellatlas/matrix-service/352). When an implementation of project-complete notifications is available, the new endpoint may act as a hook to enable E2E DCP automation.

The team agrees to a 1-week processing period to make available a project following secondary analysis completion with the current manual process. Following automation, this period will be updated to 24 hours to index the project and 48 hours for availability via the Data Browser.

#### Update

The Matrix Service does not respond to bundle updates in real-time as the service does not subscribe to DSS notifications. This is primarily due to the [Matrix cache](#matrix-cache) and the loss in performance when invalidating entries when the index is updated. The cache dramatically expedites the time to receive a matrix, however, not responding to bundle updates risks data consistency across DCP services and data availability to users.

To balance these competing motivations, the team proposes to respond to updates on a monthly cadence in the short term. In the long term, the team aims to support DCP-wide data consistency for versioned releases of HCA data. See [Reproducibility](#reproducibility) for more details on data guarantees.

The Matrix Service also does not have a migration strategy for its index and requires a full re-index to respond to metadata schema changes.

#### Delete/Redact

Deletion and redaction are handled the same way and are straightforward processes for the Matrix Service:

1. Remove all data from Redshift that is associated with bundle FQIDs from a given project UUID
2. Delete project matrices from Data Brower's S3 bucket
3. Clear the [Matrix cache](#matrix-cache)

This process is performed manually by a Matrix Service developer to ensure correct execution; it is anticipated that this process will occur infrequently. On project redaction, DataOps will open a Matrix Service ticket to request and track the process. The team adheres to a 1-week period to purge all associated data with redacted/deleted projects.

### Availability

#### Request ID

The `request_id` returned by `POST /matrix` is valid for 30 days following the successful completion of the request. Specifically, this refers to the S3 download URL to retrieve the generated matrix will be valid for 30 days. Following this time, matrices are deleted from S3 and `GET /matrix/request_id` will notify clients that the request has expired.

#### Matrix cache

Matrices are cached in S3 according to a hash of a [request's input parameters](#post-matrix). Specifically, the hash encodes the set of `cellkey`s selected by the user's `filter` object, the list of metadata `fields` exported, the output `format`, and `feature`. During a request, matching hashes short-circuit the matrix generation process for which a copy of the existing matrix is created for this request. This enables matrices to return within minutes, if not seconds, where the bottleneck of the request becomes the copy operation of the matrix.

Matrices are cached for 30 days following the most recent cache hit. The cache is cleared when data in the index is updated (e.g. project reingestion, bundle updates).

#### Project matrices

Project matrices served via the Data Browser are regenerated and updated when projects are reingested or relevant bundle updates are applied to the index.

### Reproducibility

The Matrix Service will maintain a single version of a bundle for which will be the latest version that belongs to a [version-complete](https://github.com/HumanCellAtlas/dcp-community/blob/master/rfcs/text/0015-project-completion-stage.md#definitions) project. The following reproducibility implications apply:

1. Matrices for historical versions of bundles/projects can not be generated.
2. The Matrix Service is non-deterministic over time. Identical parameters supplied to the Matrix Service at two different times does not guarantee identical outputs. 
3. The current Matrix Service does not support an implementation for Citations or Snapshots.

Given (2), (3) is true. As an on-demand service, the Matrix Service itself does not guarantee the reproducibility requirements to support Citations or Snapshots. It is proposed that an external solution to [store matrices generated by the service in the DSS](https://github.com/HumanCellAtlas/dcp-community/blob/master/rfcs/text/0014-data-citation-plan.md#phase-2---versioned-data-citations) should satisfy these requirements.

### Unresolved Questions

- [Document ID uniqueness and integrity requirements](#metadata)
- [Metadata schema migration strategy](#update)
- [Support for Citations and Snapshots](#reproducibility)

### Prior Art

*Share references to prior art to deepen community understanding of the RFC, such as learnings, adaptations from earlier designs, or community standards.*

- [Motivation Aug 2018](https://github.com/HumanCellAtlas/matrix-service/blob/d797cc96c645f90df8fcb4bb9252074931ecd108/MOTIVATION.md)
- [Use Cases Feb 2018](https://docs.google.com/document/d/12gfF3UEgRZ0YJiBoScLMtcW6Cthv0_MZHQwj4WMYKPA/edit#)
- [API v0](https://github.com/HumanCellAtlas/matrix-service/blob/1c43b9f3d757ffcb9111b5a13d46691249435f36/README.md)
  - Issues:
    - Read expression data directly from DSS which posed significant performance limitations
    - Exposed bundles via API which caused confusion and data access limitations
    - Metadata was not exported with matrices
    - `zarr` previously supported as default

